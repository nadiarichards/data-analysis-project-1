{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mega_df_playground\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'api_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-92faed0e9941>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Import API key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mapi_keys\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mg_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mapi_keys\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mweather_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'api_keys'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import seaborn as sn\n",
    "from pandas import DataFrame\n",
    "import requests\n",
    "import gmaps\n",
    "import os\n",
    "from pprint import pprint\n",
    "import re \n",
    "\n",
    "# Import API key\n",
    "from api_keys import g_key\n",
    "from api_keys import weather_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create path to read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File Resources/continent_code.csv does not exist: 'Resources/continent_code.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a2cad92f44c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Read csv and store into Pandas DataFrames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mcontinent_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontinent_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mclimate_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclimate_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mexport_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File Resources/continent_code.csv does not exist: 'Resources/continent_code.csv'"
     ]
    }
   ],
   "source": [
    "# Files to Load \n",
    "continent_file = \"Resources/continent_code.csv\"\n",
    "climate_file = \"Resources/country_climate.csv\"\n",
    "export_file = \"Resources/country_export.csv\"\n",
    "industry_file = \"Resources/country_industry.csv\"\n",
    "consumption_file = \"Resources/country_consumption.csv\"\n",
    "happiness_file = \"Resources/country_happiness.csv\"\n",
    "mental_health_file = \"Resources/mental_health.csv\"\n",
    "capitals_file = \"Resources/country_capitals.csv\"\n",
    "\n",
    "# Read csv and store into Pandas DataFrames\n",
    "continent_data = pd.read_csv(continent_file)\n",
    "climate_data = pd.read_csv(climate_file)\n",
    "export_data = pd.read_csv(export_file)\n",
    "industry_data = pd.read_csv(industry_file)\n",
    "consumption_data = pd.read_csv(consumption_file)\n",
    "happiness_data = pd.read_csv(happiness_file)\n",
    "mental_health_data = pd.read_csv(mental_health_file)\n",
    "capitals_data = pd.read_csv(capitals_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Dataframes before merge - continent_df\n",
    "continent_df = continent_data[[\"Continent_Name\",\"Three_Letter_Country_Code\"]] \n",
    "continent_df = continent_df.rename(columns={\"Three_Letter_Country_Code\": \"country_code\", \"Continent_Name\": \"continent\" })\n",
    "\n",
    "# Clean Dataframes before merge - climate_df\n",
    "climate_df = climate_data[[\"COUNTRY\",\"CLIMATE\"]]\n",
    "climate_df  = climate_df.rename(columns={\"COUNTRY\": \"country\", \"CLIMATE\": \"climate\" })\n",
    "\n",
    "# Clean Dataframes before merge - consumption_df \n",
    "consumption_df  = consumption_data.rename(columns={\"Entity\": \"country\", \"Code\": \"country_code\", \n",
    "                                                   \"Total alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)\": \"consumption_per_capita_(L)\"})\n",
    "\n",
    "# Clean Dataframes before merge - happiness_df \n",
    "happiness_df = happiness_data[[\"Country name\", \"Regional indicator\", \"Ladder score\", \"Healthy life expectancy\",\"Logged GDP per capita\"]]\n",
    "happiness_df = happiness_df.rename(columns= {\"Country name\": \"country\", \"Regional indicator\": \"region\", \"Ladder score\": \"happy_score\", \"Healthy life expectancy\": \"life_expectancy\", \"Logged GDP per capita\" : \"gdp_per_capita\"})\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Dataframes before merge - wellness_df\n",
    "wellness_df = mental_health_data.rename(columns={\"Entity\":\"country\", \"Code\": \"code\", \"Year\": \"year\", \n",
    "                                                 \"Prevalence - Mental and substance use disorders - Sex: Both - Age: Age-standardized (Percent)\": \"mental_health_and_addiction (%)\"})\n",
    "to_drop = [\"Andean Latin America\", \"Australasia\", \"Caribbean\", \"Central Asia\", \"Central Europe\", \"Central Europe, Eastern Europe, and Central Asia\",\n",
    "            \"Central Latin America\", \"Central Sub-Saharan Africa\", \"East Asia\", \"Eastern Europe\", \"Eastern Sub-Saharan Africa\",\n",
    "            \"England\", \"High SDI\", \"High Income\", \"High-income Asia Pacific\", \"High-middle SDI\", \"Latin America and Caribbean\",\n",
    "            \"Low SDI\", \"Low-middle SDI\", \"Middle SDI\", \"North Africa and Middle East\", \"North America\", \"Northern Ireland\", \"Oceania\",\n",
    "            \"Scotland\", \"South Asia\", \"Southeast Asia\", \"Southeast Asia, East Asia, and Oceania\", \"Southern Latin America\", \n",
    "            \"Southern Sub-Saharan Africa\", \"Sub-Saharan Africa\", \"Tropical Latin America\", \"Wales\", \"Western Europe\", \"Western Sub-Saharan Africa\",\n",
    "            \"World\"] \n",
    "wellness_df = wellness_df[~wellness_df['country'].isin(to_drop)]\n",
    "wellness_df = wellness_df[wellness_df['code'].notna()]\n",
    "\n",
    "# Create a new dataframe to show the avg percentage of mental health and addiction observed for each country\n",
    "wellness_subset = wellness_df.groupby(['code'])\n",
    "average_wellness_df = wellness_subset.mean()\n",
    "country_mask = wellness_df.groupby(\"country\")\n",
    "wellness_df = country_mask.first() \n",
    "\n",
    "wellness_df = wellness_df.drop(columns=['year'])\n",
    "#wellness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Dataframes before merge - capitals_df\n",
    "capitals_data.shape[0] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge DataFrames\n",
    "* df_2 = continent_df + consumption_df\n",
    "* df_3 = continent_df + consumption_df + climate_df\n",
    "* df_4 = continent_df + consumption_df + climate_df + export_data\n",
    "* df_5 = continent_df + consumption_df + climate_df + export_data + industry_data\n",
    "* df_6 = continent_df + consumption_df + climate_df + export_data + industry_data + happiness_df\n",
    "* df_7 = continent_df + consumption_df + climate_df + export_data + industry_data + happiness_df + wellness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data into a single dataset.  \n",
    "df_2 = pd.merge(continent_df, consumption_df, how=\"outer\", on=[\"country_code\", \"country_code\"])  \n",
    "df_3 = pd.merge(df_2, climate_df, how=\"outer\", on=[\"country\", \"country\"]) \n",
    "df_4 = pd.merge(df_3, export_data, how=\"outer\", on=[\"country\", \"country\"]) \n",
    "df_5 = pd.merge(df_4, industry_data, how=\"outer\", on=[\"country\", \"country\"]) \n",
    "df_6 = pd.merge(df_5, happiness_df, how=\"outer\", on=[\"country\", \"country\"]) \n",
    "df_7 = pd.merge(df_6, wellness_df, how=\"outer\", on=[\"country\", \"country\"]) \n",
    "df_8 = pd.merge(df_7, capitals_data, how=\"outer\",on=[\"country\", \"country\"])\n",
    "\n",
    "# Remove all rows where continent == 'Antartica'\n",
    "to_drop = ['Antarctica']\n",
    "df_9 = df_8[~df_8['continent'].isin(to_drop)]\n",
    "df_9.count() \n",
    "\n",
    "# Remove all rows where there is no value for alcohol consumption \n",
    "df_10 = df_9[df_9['consumption_per_capita_(L)'].notna()] \n",
    "df_10.count() \n",
    "\n",
    "\n",
    "# Remove all non-countries within 'country' column\n",
    "to_drop = ['Arab World', 'Caribbean small states', 'Central Europe and the Baltics', 'Early-demographic dividend',\n",
    "          'East Asia & Pacific', 'East Asia & Pacific (IDA & IBRD)', 'East Asia & Pacific (excluding high income)',\n",
    "          'Euro area', 'Europe & Central Asia', 'Europe & Central Asia (IDA & IBRD)', 'Europe & Central Asia (excluding high income)',\n",
    "          'European Union', 'Fragile and conflict affected situations', 'Heavily indebted poor countries (HIPC)', 'High income',\n",
    "          'IBRD only', 'IDA & IBRD total', 'IDA blend', 'IDA only', 'IDA total', 'Late-demographic dividend', 'Latin America & Caribbean', 'Latin America & Caribbean (IDA & IBRD)', 'Latin America & Caribbean (excluding high income)',\n",
    "          'Least developed countries: UN classification', 'Low & middle income', 'Low income', 'Lower middle income','Middle East & North Africa', 'Middle East & North Africa (IDA & IBRD)','Middle East & North Africa (excluding high income)',\n",
    "          'Middle income', 'North America', 'OECD members', 'Other small states', 'Pacific island small states',\n",
    "          'Post-demographic dividend', 'Pre-demographic dividend','Small states', 'South Asia', 'South Asia (IDA & IBRD)',\n",
    "          'Sub-Saharan Africa', 'Sub-Saharan Africa (IDA & IBRD)', 'Sub-Saharan Africa (excluding high income)',\n",
    "          'Syrian Arab Republic', 'Upper middle income', 'World']\n",
    "df_11 = df_10[~df_10['country'].isin(to_drop)]\n",
    "df_11.count() \n",
    "\n",
    "# Remove all duplicate countries --> Azerbaijan, Armenia, Cypress, Georgia, Kazakstan, Turkey\n",
    "df_12 = df_11.drop_duplicates(subset=['country'])\n",
    "\n",
    "df_12 = df_12.reset_index() \n",
    "\n",
    "df_12.head() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data to csv\n",
    "df_12.to_csv(\"mega_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary\n",
    "* Display a list of columns in the dataset\n",
    "* Display a list of regions in the dataset\n",
    "* Display a list of countries in the dataset\n",
    "* Calculate total number of countries\n",
    "* Calculate overall average alcohol consumption\n",
    "* Calculate total years of data compiled for each country \n",
    "* Determine which year(s) have the most data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display a list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_12.columns\n",
    "columns_string =', '.join(columns)\n",
    "print(f\"List of column names: {columns_string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a list of regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = df_12[\"region\"].unique()\n",
    "regions_string = \", \".join(map(str, regions))\n",
    "\n",
    "print(f\"List of regions represented in the dataset: {regions_string}\")\n",
    "regions\n",
    "\n",
    "DataFrame.dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a list of countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df_12[\"country\"].unique()\n",
    "countries_string = ', '.join(countries)\n",
    "\n",
    "print(f\"List of countries represented in the dataset: {countries_string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Calculate how many countries are represented in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_countries = df_12.shape[0] \n",
    "print(f'The total number of rows countries represented in the dataset are {total_countries}.') \n",
    "\n",
    "# Alternative methods:\n",
    "#number_countries = df_11['country'].nunique()\n",
    "# unique_countries = df_8['country'].unique()\n",
    "# number_countries = len(unique_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the overall average alcohol consumption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_avg_consumption = df_12[\"consumption_per_capita_(L)\"].mean() \n",
    "overall_avg_consumption\n",
    "formatted_consumption = round(overall_avg_consumption,2)\n",
    "\n",
    "print(f\"The overall average of alcohol consumption per capita (liters) among countries represented in the dataset is {overall_avg_consumption}.\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the 10 countries that consumes the most alcohol \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mask = df_12.groupby(\"country\")\n",
    "country_subset = country_mask.first()\n",
    "\n",
    "\n",
    "high_consumption = country_subset.sort_values([(\"consumption_per_capita_(L)\")], ascending=False).head(n=10)\n",
    "high_consumption.reset_index() \n",
    "\n",
    "high_consumption_series = high_consumption[\"consumption_per_capita_(L)\"], high_consumption[\"capital\"] \n",
    "\n",
    "high_consumption_df = pd.DataFrame(high_consumption_series)\n",
    "high_consumption_df = high_consumption_df.transpose()\n",
    "\n",
    "most_alcohol = high_consumption_df.index.tolist()\n",
    "\n",
    "print(\"The countries with the highest consumption rates are \" + \", \".join(most_alcohol))\n",
    "\n",
    "capitals = high_consumption_df['capital'].tolist()  \n",
    "\n",
    "capitals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find latitude and longitude for the 10 countries with the highest consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config information.\n",
    "url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "units = \"metric\"\n",
    "\n",
    "# Build partial query URL\n",
    "query_url = f\"{url}appid={weather_key}&units={units}&q=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert capital column to list\n",
    "capitals = high_consumption_df['capital'].tolist()  \n",
    "\n",
    "# Create container for list of capitals\n",
    "cities = ['Chisinau','Vilnius','Prague','Abuja','Berlin','Luxembourg','Dublin','Riga','Sofia','Ljubljana']\n",
    "\n",
    "# Set up lists to hold reponse info\n",
    "lat = []\n",
    "lon = []\n",
    "\n",
    "# Loop through the list of cities and perform a request for data on each\n",
    "for city in cities:\n",
    "    response = requests.get(query_url + city).json()\n",
    "    lat.append(response['coord']['lat'])\n",
    "    lon.append(response['coord']['lon'])\n",
    "\n",
    "print(f\"The latitude information received is: {lat}\")\n",
    "print(f\"The longitude information received is: {lon}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add latitude and longitude columns to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_consumption_df['latitude'] = lat\n",
    "high_consumption_df['longitude'] = lon\n",
    "\n",
    "high_consumption_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a heatmap to display the drunkest countries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure gmaps with API key\n",
    "gmaps.configure(api_key=g_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store 'Lat' and 'Lng' into  locations \n",
    "locations = high_consumption_df[[\"latitude\", \"longitude\"]]\n",
    "\n",
    "# Create a poverty Heatmap layer\n",
    "fig = gmaps.figure(center=[10,15], zoom_level=2)\n",
    "\n",
    "heat_layer = gmaps.heatmap_layer(locations, weights=high_consumption_df['consumption_per_capita_(L)'], dissipating=False, max_intensity=15, point_radius = 4)\n",
    "\n",
    "fig.add_layer(heat_layer)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the 10 countries that consumes the least alcohol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_consumption = country_subset.sort_values([(\"consumption_per_capita_(L)\")], ascending=True).head(n=10)\n",
    "low_consumption.reset_index() \n",
    "\n",
    "low_consumption_series = low_consumption[\"consumption_per_capita_(L)\"]  \n",
    "low_consumption_df = pd.DataFrame(low_consumption_series)\n",
    "\n",
    "least_alcohol = low_consumption_df.index.tolist()\n",
    "\n",
    "print(\"The countries with the lowest consumption rates are \" + \", \".join(least_alcohol))\n",
    "\n",
    "low_consumption_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"List of column names: {columns_string}\")\n",
    "print(\"------------------------------------------------------------------------------------------\")\n",
    "print(f\"List of regions represented in the dataset: {regions_string}\")\n",
    "print(\"------------------------------------------------------------------------------------------\")\n",
    "print(f\"List of countries represented in the dataset: {countries_string}\")\n",
    "print(\"------------------------------------------------------------------------------------------\")\n",
    "print(f\"Total number of countries represented in the dataset: {total_countries}\")\n",
    "print(\"------------------------------------------------------------------------------------------\")\n",
    "print(f\"Overall average of alcohol consumption per capita (liters): {formatted_consumption}\") \n",
    "print(\"------------------------------------------------------------------------------------------\")\n",
    "print(\"The 10 countries with the highest consumption rates of alcohol: \" + \", \".join(most_alcohol))\n",
    "print(\"------------------------------------------------------------------------------------------\")\n",
    "print(\"The 10 countries with the lowest consumption rates of alchohol: \" + \", \".join(least_alcohol)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Three  - Consumption & Geography -  Continent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a for loop to find consumption averages by continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create containers to hold aggregate values for each continent in for loop\n",
    "continents = ['Africa', 'Asia', 'Europe', 'North America', 'South America', 'Oceania'] \n",
    "segment_values = []\n",
    "number_countries = []\n",
    "\n",
    "# Filter each segment from our list 'continent' in the dataframe\n",
    "for continent in continents:\n",
    "    df = country_subset.loc[country_subset[\"continent\"] == continent]\n",
    "    # Aggregate the consumption values for each continent in the dataframe\n",
    "    values = df['consumption_per_capita_(L)'].sum()\n",
    "    segment_values.append(values)\n",
    "    # Find number of countries for each continent in the dataframe\n",
    "    consumption_by_segment = len(df)\n",
    "    number_countries.append(consumption_by_segment)\n",
    "    # Find the average consumption for each continent\n",
    "    # Division is not a supported operation on lists so use np.array to perform a function\n",
    "    avg_consumption_by_continent = np.array([segment_values]) / np.array([number_countries])\n",
    "    \n",
    "    \n",
    "#print(avg_consumption_by_continent[0][0])\n",
    "#print(segment_values)\n",
    "#print(number_countries) \n",
    "\n",
    "df = pd.DataFrame({\"continent\": continents, \"total_consumption(liters)\": segment_values, \"avg_consumption(liters)\": avg_consumption_by_continent [0], \"num_countries\": number_countries})\n",
    "df = df.sort_values(\"avg_consumption(liters)\", ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a boxplot to compare consumption values for each continent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for every country\n",
    "#type(df_12)\n",
    "\n",
    "df_12.boxplot(\"consumption_per_capita_(L)\",by=\"continent\", figsize=(10,5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create containers and conditionals for for loop\n",
    "continents = ['Africa', 'Asia', 'Europe', 'North America', 'South America', 'Oceania']\n",
    "values = []\n",
    "\n",
    "# Step 6: Locate each drug from our list 'drugs' in the orginal dataframe\n",
    "for continent in continents:\n",
    "    df = country_subset.loc[country_subset[\"continent\"] == continent]\n",
    "    \n",
    "    # Create a series that consists of all final volume values for each regimen\n",
    "    values = df['consumption_per_capita_(L)']\n",
    "    \n",
    "    # Calculate and print the interquartile range (IQR) for each regimen\n",
    "    quartiles = values.quantile([.25,.5,.75])\n",
    "    lowerq = quartiles[0.25]\n",
    "    upperq = quartiles[0.75]\n",
    "    iqr = upperq-lowerq\n",
    "    print(f'IQR for {continent}: {iqr}')\n",
    "    \n",
    "    # Find upper and lower bounds to help identify outliers for each regimen\n",
    "    lower_bound = lowerq - (1.5*iqr)\n",
    "    upper_bound = upperq + (1.5*iqr)\n",
    "    print(f'Lower Bound for {continent}: {lower_bound}')\n",
    "    print(f'Upper Bound for {continent}: {upper_bound}')\n",
    "    \n",
    "    # Quantitatively check for outliers\n",
    "    outliers_count = (values.loc[(df['consumption_per_capita_(L)'] >= upper_bound) | \n",
    "                                        (df['consumption_per_capita_(L)'] <= lower_bound)]).count()\n",
    "    print(f'Number of {continent} outliers: {outliers_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the outliers in the Oceania subset data\n",
    "oceania_df = country_subset.loc[country_subset['continent'] == 'Oceania']\n",
    "outliers_oceania = oceania_df.loc[(oceania_df['consumption_per_capita_(L)'] >= 7.3500000000000005) | \n",
    "                                        (oceania_df['consumption_per_capita_(L)'] <= -2.250000000000001)] \n",
    "outliers_oceania\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the outliers in the Europe subset data\n",
    "europe_df = country_subset.loc[country_subset['continent'] == 'Europe']\n",
    "outliers_europe = europe_df.loc[(europe_df['consumption_per_capita_(L)'] >= 17.687500000000004) | \n",
    "                                        (europe_df['consumption_per_capita_(L)'] <= 3.1874999999999973)] \n",
    "outliers_europe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumption by Continent - Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumption - Asia\n",
    "asia_df = country_subset.loc[country_subset[\"continent\"] == \"Asia\"]\n",
    "asia_consumption = asia_df['consumption_per_capita_(L)'].sum()\n",
    "countries_in_asia = len(asia_df)\n",
    "\n",
    "avg_consumption_asia = asia_consumption / countries_in_asia\n",
    "avg_consumption_asia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumption by Continent - Oceania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumption - Oceania\n",
    "oceania_df = country_subset.loc[country_subset[\"continent\"] == \"Oceania\"]\n",
    "oceania_consumption = asia_df['consumption_per_capita_(L)'].sum()\n",
    "countries_in_oceania = len(oceania_df)\n",
    "\n",
    "avg_consumption_oceania = oceania_consumption / countries_in_oceania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumption by Continent - Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumption - Africa\n",
    "africa_df = country_subset.loc[country_subset[\"continent\"] == \"Africa\"]\n",
    "africa_consumption = africa_df['consumption_per_capita_(L)'].sum()\n",
    "countries_in_africa = len(africa_df)\n",
    "\n",
    "avg_consumption_africa = africa_consumption / countries_in_africa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumption by Continent - North America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumption - North America\n",
    "north_america_df = country_subset.loc[country_subset[\"continent\"] == \"North America\"]\n",
    "north_america_consumption = north_america_df['consumption_per_capita_(L)'].sum()\n",
    "countries_in_north_america = len(north_america_df)\n",
    "\n",
    "avg_consumption_north_america = north_america_consumption / countries_in_north_america"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumption by Continent - Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumption - Europe\n",
    "europe_df = country_subset.loc[country_subset[\"continent\"] == \"Europe\"]\n",
    "europe_consumption = europe_df['consumption_per_capita_(L)'].sum()\n",
    "countries_in_europe = len(europe_df)\n",
    "\n",
    "avg_consumption_europe = europe_consumption / countries_in_europe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumption by Continent - South America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumption - South America\n",
    "south_america_df = country_subset.loc[country_subset[\"continent\"] == \"South America\"]\n",
    "south_america_consumption = south_america_df['consumption_per_capita_(L)'].sum()\n",
    "countries_in_south_america = len(south_america_df)\n",
    "\n",
    "avg_consumption_south_america = south_america_consumption / countries_in_south_america"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumption by Continent -  Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_consumption_asia)\n",
    "print(avg_consumption_oceania)\n",
    "print(avg_consumption_africa)\n",
    "print(avg_consumption_north_america)\n",
    "print(avg_consumption_europe)\n",
    "print(avg_consumption_south_america)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumption by Continent - Bar Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x and y axis\n",
    "y = [avg_consumption_asia, avg_consumption_oceania, avg_consumption_africa, avg_consumption_north_america, avg_consumption_europe, avg_consumption_south_america ]\n",
    "x = np.arange(len(y)) \n",
    "\n",
    "# Plot bar graph\n",
    "plt.bar(x, y, color='r', alpha=0.5, align=\"center\")\n",
    "\n",
    "# Add Labels\n",
    "tick_locations = [value for value in x]\n",
    "plt.xticks(tick_locations, [\"Asia\", \"Oceania\", \"Africa\", \"North America\", \"Europe\", \"South America\"])\n",
    "plt.title(\"Alcohol Consumption By Continent\")\n",
    "plt.xlabel(\"Continent\")\n",
    "plt.ylabel(\"Average Alcohol Consumption Per Capita (Liters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part Three  - Consumption & Geography - Region "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a for loop to find consumption averages by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_subset[\"region\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create containers to hold aggregate values for each continent in for loop\n",
    "region = ['Sub-Saharan Africa ', 'Latin America and Caribbean', 'Western Europe', 'Middle East and North Africa',\n",
    "          'Central and Eastern Europe', 'Commonwealth of Independent States', 'Southeast Asia',\n",
    "          'North America and ANZ','East Asia'] \n",
    "segment_values = []\n",
    "number_countries = []\n",
    "\n",
    "# Filter each segment from our list 'continent' in the dataframe\n",
    "for continent in continent:\n",
    "    df = country_subset.loc[country_subset[\"continent\"] == continent]\n",
    "    # Aggregate the consumption values for each continent in the dataframe\n",
    "    values = df['consumption_per_capita_(L)'].sum()\n",
    "    segment_values.append(values)\n",
    "    # Find number of countries for each continent in the dataframe\n",
    "    consumption_by_segment = len(df)\n",
    "    number_countries.append(consumption_by_segment)\n",
    "    # Find the average consumption for each continent\n",
    "    # Division is not a supported operation on lists so use np.array to perform a function\n",
    "    avg_consumption_by_region = np.array([segment_values]) / np.array([number_countries])\n",
    "    \n",
    "print(avg_consumption_by_region)\n",
    "print(segment_values)\n",
    "print(number_countries) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12.boxplot(\"consumption_per_capita_(L)\", by=\"region\", figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all exports related to oil and petroleum\n",
    "df_11['main_export'] = df_11['main_export'].replace({\"Crude oil\": \"Oil\"}) \n",
    "df_11['main_export'] = df_11.loc['main_export'].replace({\"Petroleum\": \"Oil\"}) \n",
    "# df_11['main_export'] = df_11.loc['main_export'].replace({\"Crude oil and petroleum products\": \"Oil\"}) \n",
    "# df_11['main_export'] = df_11.loc['main_export'].replace({\"Oil and gas\": \"Oil\"}) \n",
    "# df_11['main_export'] = df_11.loc['main_export'].replace({\"Fuels and fuel products\": \"Oil\"}) \n",
    "# df_11['main_export'] = df_11.loc['main_export'].replace({\"Petroleum and petroleum products\": \"Oil\"}) \n",
    "\n",
    "# # Merge all exports related to electronics\n",
    "# df_11['main_export'] = df_11.loc['main_export'].replace({\"Electronic equipment\": \"Electronic products\"}) \n",
    "  \n",
    "#.loc[row_index,col_indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part Four  - Economy - Industry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Five - Correlation & Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore potential relationships by creating correlation matrix\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "df_12_corr = df_12.corr()\n",
    "df_12_corr.unstack().sort_values()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15.0, 10.0)\n",
    "figure = (sn.heatmap(df_12_corr, annot=True,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
